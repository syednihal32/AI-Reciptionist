# ğŸ¤ AI Voice Receptionist Agent â€“ Audio Call Simulator

**A smart, production-ready AI receptionist that processes voice calls, understands intent, and generates intelligent responses. Designed for easy integration with Twilio for real phone calls.**

---

## ğŸ“‹ Overview

This project implements an **AI-powered voice receptionist** that:

- **Accepts voice input** (simulated phone calls via audio file upload for now)
- **Transcribes speech to text** using local Whisper (faster-whisper)
- **Understands intent** using LLM (Groq Llama 3 or Google Gemini)
- **Generates smart replies** with a receptionist-style system prompt
- **Converts text to speech** using Edge-TTS or gTTS
- **Stores conversations** in SQLite for history and analytics
- **Provides a clean UI** with Streamlit for easy demo and interaction
- **Maintains Twilio-ready architecture** for future real phone integration

**Key Features:**
- âœ… Zero paid dependencies (all free/open-source)
- âœ… Local speech processing (no cloud STT required)
- âœ… Fast LLM inference via Groq free tier
- âœ… Modular, clean code architecture
- âœ… Easy to extend and customize
- âœ… Production-ready error handling

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STREAMLIT FRONTEND                        â”‚
â”‚  (Audio Upload, Chat Display, Conversation History)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ HTTP (REST API)
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FASTAPI BACKEND                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  /process_audio  â†’  STT â†’ LLM â†’ TTS â†’ DB â†’ Response â”‚   â”‚
â”‚  â”‚  /conversations  â†’  Query conversation history       â”‚   â”‚
â”‚  â”‚  /health         â†’  Health check                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚              â”‚              â”‚              â”‚
      â–¼              â–¼              â–¼              â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚Whisper â”‚    â”‚ Groq   â”‚    â”‚Edge-TTSâ”‚    â”‚SQLite  â”‚
  â”‚  STT   â”‚    â”‚ LLM    â”‚    â”‚  TTS   â”‚    â”‚  DB    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Data Flow:**
1. User uploads audio file via Streamlit
2. FastAPI receives file and saves temporarily
3. **STT Module** (Whisper) transcribes audio â†’ text
4. **LLM Module** (Groq) generates AI reply + intent
5. **TTS Module** (Edge-TTS) synthesizes reply â†’ audio
6. **DB Module** (SQLAlchemy + SQLite) stores conversation
7. Streamlit displays results and plays audio response

**Future Twilio Integration:**
- Replace "file upload" with "Twilio webhook audio"
- Add `/twilio-webhook` endpoint (see `backend/twilio_stub.py`)
- Same processing pipeline, different audio source

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **pip** (Python package manager)
- **Groq API Key** (free tier available at https://console.groq.com/keys)

### Installation

#### 1. Clone/Download the Project

```bash
cd ai_voice_receptionist
```

#### 2. Create Virtual Environment

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux
python3 -m venv venv
source venv/bin/activate
```

#### 3. Install Backend Dependencies

```bash
cd backend
pip install -r requirements.txt
cd ..
```

#### 4. Install Frontend Dependencies

```bash
cd frontend
pip install -r requirements.txt
cd ..
```

#### 5. Configure Environment

```bash
# Copy example config
cp .env.example .env

# Edit .env and add your Groq API key
# LLM_PROVIDER=groq
# GROQ_API_KEY=your_actual_key_here
```

Get your **Groq API Key** for free:
1. Go to https://console.groq.com/keys
2. Sign up (free account)
3. Create an API key
4. Copy it to `.env`

#### 6. Run Backend

```bash
# From project root
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

You should see:
```
âœ“ Database initialized successfully.
âœ“ Backend initialized successfully.
Uvicorn running on http://0.0.0.0:8000
```

#### 7. Run Frontend (in a new terminal)

```bash
# Activate venv first
# Windows: venv\Scripts\activate
# macOS/Linux: source venv/bin/activate

streamlit run frontend/app.py
```

Streamlit will open in your browser at `http://localhost:8501`

---

## ğŸ“– Usage

### Demo Flow

1. **Open Streamlit UI** at `http://localhost:8501`
2. **Check Backend Status** in sidebar (should show "âœ“ Backend Online")
3. **Upload Audio File**
   - Click "Choose an audio file"
   - Select a WAV or MP3 file
   - Preview plays in the UI
4. **Process Call**
   - Click "ğŸ¯ Process Call" button
   - Wait for processing (STT â†’ LLM â†’ TTS)
5. **View Results**
   - See transcription of what the caller said
   - See AI receptionist's reply
   - See inferred intent (scheduling, support, etc.)
   - Listen to the AI's voice response
6. **Check History**
   - Right panel shows recent conversations
   - Filter by intent if desired
   - Click "ğŸ”„ Refresh History" to update

### Example Calls to Try

**Scheduling Request:**
- "Hi, I'd like to schedule an appointment for next Tuesday at 2 PM."
- Expected intent: `scheduling`

**Order Status:**
- "Can you check on my order? Order number 12345."
- Expected intent: `order_status`

**Support Request:**
- "I'm having trouble logging into my account. Can you help?"
- Expected intent: `support`

**General Inquiry:**
- "What are your office hours?"
- Expected intent: `general`

---

## ğŸ”Œ API Endpoints

### Health Check
```
GET /health
```
Returns backend status and configuration.

### Process Audio
```
POST /process_audio
Content-Type: multipart/form-data

Body:
  file: <audio_file>

Response:
{
  "success": true,
  "transcription": "Hi, I'd like to schedule an appointment",
  "reply_text": "I'd be happy to help! What date works best for you?",
  "intent": "scheduling",
  "reply_audio_url": "/audio/reply_20231215_143022_abc123.mp3",
  "timestamp": "2023-12-15T14:30:22.123456"
}
```

### Get Conversations
```
GET /conversations?limit=20&intent=scheduling

Response:
{
  "success": true,
  "count": 5,
  "conversations": [
    {
      "id": 1,
      "user_text": "...",
      "ai_text": "...",
      "intent": "scheduling",
      "created_at": "2023-12-15T14:30:22"
    },
    ...
  ]
}
```

---

## ğŸ“ Project Structure

```
ai_voice_receptionist/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI app & endpoints
â”‚   â”œâ”€â”€ config.py            # Configuration management
â”‚   â”œâ”€â”€ db.py                # Database & ORM
â”‚   â”œâ”€â”€ stt.py               # Speech-to-Text (Whisper)
â”‚   â”œâ”€â”€ tts.py               # Text-to-Speech (Edge-TTS/gTTS)
â”‚   â”œâ”€â”€ llm_engine.py        # LLM (Groq/Gemini)
â”‚   â”œâ”€â”€ twilio_stub.py       # Twilio integration placeholder
â”‚   â”œâ”€â”€ utils.py             # Helper functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ requirements.txt      # Backend dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app.py               # Streamlit UI
â”‚   â””â”€â”€ requirements.txt      # Frontend dependencies
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ conversations.db     # SQLite database (auto-created)
â”‚   â”œâ”€â”€ audio_responses/     # Generated TTS audio files
â”‚   â””â”€â”€ temp_audio/          # Temporary audio files
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ ARCHITECTURE.md      # Detailed architecture
â”‚   â””â”€â”€ DEMO_FLOW.md         # Demo presentation guide
â”‚
â”œâ”€â”€ .env.example             # Environment configuration template
â”œâ”€â”€ README.md                # This file
â””â”€â”€ .gitignore               # Git ignore rules
```

---

## âš™ï¸ Configuration

All configuration is managed via `.env` file. Key variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `LLM_PROVIDER` | `groq` | LLM provider: `groq` or `gemini` |
| `GROQ_API_KEY` | - | Your Groq API key (required) |
| `GROQ_MODEL` | `llama3-8b-instant` | Groq model to use |
| `COMPANY_NAME` | `Acme Corp` | Company name for receptionist |
| `DB_URL` | `sqlite:///./data/conversations.db` | Database URL |
| `AUDIO_OUTPUT_DIR` | `./data/audio_responses` | Where to save generated audio |
| `BACKEND_HOST` | `0.0.0.0` | Backend server host |
| `BACKEND_PORT` | `8000` | Backend server port |

---

## ğŸ”® Future Enhancements

### Phase 1: Real Phone Integration (Twilio)
- [ ] Implement `/twilio-webhook` endpoint
- [ ] Add Twilio SDK to requirements
- [ ] Configure Twilio phone number with webhook
- [ ] Test with real phone calls
- [ ] Add call recording and analytics

### Phase 2: Advanced Features
- [ ] Multi-turn conversations (context awareness)
- [ ] Appointment calendar integration
- [ ] CRM integration for customer data
- [ ] Sentiment analysis
- [ ] Call transfer to human agents
- [ ] Advanced intent classification (NLU)

### Phase 3: Optimization
- [ ] GPU acceleration for Whisper
- [ ] Model quantization for faster inference
- [ ] Caching for common responses
- [ ] Load balancing for multiple instances
- [ ] Advanced monitoring and logging

### Phase 4: Deployment
- [ ] Docker containerization
- [ ] Kubernetes orchestration
- [ ] CI/CD pipeline
- [ ] Production-grade logging
- [ ] Performance monitoring

---

## ğŸ› Troubleshooting

### Backend won't start
**Error:** `GROQ_API_KEY not set`
- **Solution:** Add your Groq API key to `.env` file

**Error:** `Port 8000 already in use`
- **Solution:** Change `BACKEND_PORT` in `.env` or kill the process using port 8000

### Frontend can't connect to backend
**Error:** `Backend Offline` in sidebar
- **Solution:** Make sure backend is running on `http://localhost:8000`
- Check `BACKEND_BASE_URL` in `.env`

### Audio processing fails
**Error:** `No speech detected in audio file`
- **Solution:** Upload a file with clear speech, not silence or music

**Error:** `Transcription failed`
- **Solution:** Try a shorter audio file or ensure audio quality is good

### Out of memory
**Error:** `CUDA out of memory` or similar
- **Solution:** Whisper is using GPU. Set `device="cpu"` in `backend/stt.py`

---

## ğŸ“Š Performance Notes

- **STT (Whisper):** ~5-15 seconds for 30-second audio (CPU)
- **LLM (Groq):** ~1-2 seconds for reply generation
- **TTS (Edge-TTS):** ~1-3 seconds for audio synthesis
- **Total:** ~10-25 seconds per call (depends on audio length)

**Optimization Tips:**
- Use GPU for Whisper if available (set `device="cuda"`)
- Use smaller Whisper model (`tiny` or `base`) for speed
- Cache common responses
- Use async processing for multiple calls

---

## ğŸ“ License

This project is created for the 48-Hour AI Agent Development Challenge.

---

## ğŸ¤ Support

For issues or questions:
1. Check the `docs/` folder for detailed documentation
2. Review error messages in backend logs
3. Verify `.env` configuration
4. Check that all dependencies are installed

---

## ğŸ¯ Key Takeaways

âœ… **Zero-cost deployment** â€“ All free/open-source tools
âœ… **Production-ready** â€“ Clean code, error handling, logging
âœ… **Extensible** â€“ Easy to add features or swap components
âœ… **Twilio-ready** â€“ Architecture supports real phone integration
âœ… **Fast** â€“ Groq provides fast LLM inference
âœ… **Local** â€“ No cloud dependencies for core processing

---

**Built with â¤ï¸ for the 48-Hour AI Agent Development Challenge**
